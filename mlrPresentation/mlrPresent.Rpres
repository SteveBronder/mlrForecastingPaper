Forecasting in the MLR Framework
========================================================
author: Steve Bronder
date: October 11th, 2016
autosize: false

<style>
.small-code pre code {
  font-size: 1em;
}
</style>

Goal: Make Forecasting Simple
========================================================

> "We need to stop teaching abstinence and start teaching safe statistics"
- Hadley Wickham

Ex: Demeaning the whole data set before CV

- Forecasting is very dangerous
- Need a framework for 'safe forecasting'
- Want to use ML in forecasting

The Modeling Process
========================================================

<img src="modeling_process.jpeg" alt="Drawing" style="width: 1400px; height: 500px"/>

***

<img src="mlr_flow.jpeg" alt="Drawing" style="width: 2000px; height: 500px"/>

Example Data
======================================================
class: small-code 

```{r quandl, cache = TRUE, fig.align='center',fig.height= 12, fig.width= 15}
library(M4comp)
library(xts)
library(lubridate)
m4Fin1 <- M4[[8836]]
m4Train1 <- xts(m4Fin1$past, as.POSIXct("2007-12-05") + days(0:I(length(m4Fin1$past)-1)))
m4Test1 <- xts(m4Fin1$future, as.POSIXct("2009-09-06") + days(0:I(length(m4Fin1$future)-1)))
colnames(m4Train1) <- "target_var"
colnames(m4Test1) <- "target_var"

```

Plot of Climate Data
=====================================================
class: small-code 

```{r quandlPlot, cache = TRUE, fig.align='center',fig.height= 8, fig.width= 10, echo = FALSE}
plot(m4Train1, main = "Daily Climate Data")

```

Creating a Forecasting Task
========================================================
class: small-code 

```{r climateTask, cache = TRUE}
library(mlr)
climate.task = makeForecastRegrTask(id = "M4 Climate Data",data = m4Train1,
                                    target = "target_var",frequency = 365L)
climate.task
```

Making a Forecasting Learner
======================================================
class: small-code 

```{r arimaLearner, cache = TRUE}
tbatsMod =makeLearner("fcregr.tbats",
                      use.box.cox = FALSE,
                      use.trend = TRUE,
                      seasonal.periods = TRUE,
                      max.p = 3, max.q = 2,
                      stationary = FALSE,
                      use.arma.errors = TRUE, h = 35)
tbatsMod
```

Train a Forecast Learner
======================================================
class: small-code 

```{r trainArima, cache = TRUE}
trainTbats= train(tbatsMod, climate.task )
trainTbats

```

Predict With a Forecast Learner
======================================================
class: small-code 

```{r predictArima2, cache = TRUE}
testp = predict(trainTbats, newdata = m4Test1)
performance(testp, mase, task = climate.task)
mase
```

Prediction Plot
=====================================================
class: small-code 

```{r predplotArima, cache = TRUE, echo = FALSE, fig.align='center',fig.height= 8, fig.width= 10}
matplot(testp$data, type = "l", main = "Prediction Vs. Real Values\n For Model with No Tuning")
```


Tuning a Model
=====================================================
class: small-code 

```{r makeTuneParam, cache = TRUE}
parSet = makeParamSet(
  makeLogicalParam(id = "use.box.cox", default = FALSE, tunable = TRUE),
  makeLogicalParam(id = "use.trend", default = FALSE, tunable = TRUE),
  makeLogicalParam(id = "use.damped.trend", default = FALSE, tunable = TRUE),
  makeLogicalParam(id = "seasonal.periods", default = FALSE, tunable = TRUE),
  makeIntegerParam(id = "max.p", upper = 20, lower = 0),
  makeIntegerParam(id = "start.p", upper = 10, lower = 1, 
                   trafo = function(x) x*2),
  makeIntegerParam(id = "max.q", upper = 20, lower = 0),
  makeIntegerParam(id = "start.q", upper = 10,lower = 1,
                   trafo = function(x) x*2),
  makeIntegerParam("max.P", lower = 0, upper = 5),
  makeIntegerParam("max.Q", lower = 0, upper = 5),
  makeDiscreteParam("ic", values = c("aicc","aic","bic")),
  makeDiscreteParam("test", values = c("kpss","adf","pp")),
  makeDiscreteParam("seasonal.test", values = c("ocsb", "ch")),
  makeLogicalParam("biasadj", default = FALSE)
  )
```


Make a Tune Control Scheme
=====================================================
class: small-code 

```{r makeTuneControl, cache = TRUE}
#Specify tune by grid estimation
ctrl = makeTuneControlIrace(maxExperiments = 500L)
ctrl
```

Making a Resample Scheme
========================================
class: small-code 

```{r resampleScheme, cache = TRUE}
resampDesc = makeResampleDesc("GrowingCV", horizon = 35L,
                               initial.window = .90,
                               size = nrow(getTaskData(climate.task)), skip = .01)
resampDesc
```

Example of Windowing Resample
======================================================
<center>
<img src="caret_window.png" alt="Drawing" style="width: 1200px; height: 600px"/>
</center>

Tuning Over Parameter Space
===========================================
class: small-code 

```{r tuneSpace, eval = FALSE}
library("parallelMap")
parallelStartSocket(6)
tbatsTune = tuneParams(makeLearner("fcregr.tbats",h = 35), 
                       task = climate.task,
                       resampling = resampDesc,
                       par.set = parSet,
                       control = ctrl,
                       measures = mase)
parallelStop()
tbatsTune
```

```{r loadTune, echo = FALSE}
load("./../tbatsTune.RData")
tbatsTune
```


Training Best Model
=========================================
class: small-code 

```{r runBest, cache = TRUE}
lrn = setHyperPars(makeLearner("fcregr.tbats"), par.vals = tbatsTune$x)
m = train(lrn, climate.task)
m
```

Prediction With Best Model
=========================================
class: small-code 

```{r predBest, cache = TRUE}
climate.pred = predict(m, newdata = m4Test1)
performance(climate.pred, measures = mase, task = climate.task)
```

Prediction Plot With Best Model
=========================================
class: small-code 

```{r predplottbats, cache = TRUE, echo = FALSE, fig.align='center',fig.height= 8, fig.width= 10}

matplot(climate.pred$data, type = "l", main = "Prediction Vs. Real Data \n With Tuned Model")

```

Using an ML Model: Ensemble Forecasts
=========================================
class: small-code 

1. Train multiple forecasting models
2. Perform windowed cross validation, saving each forecast
3. Train an ML model on the forecasts



Using an ML Model: Ensemble Forecasts Covariance Parameter Space
=========================================

class: small-code 
```{r mlLagTask, cache = TRUE}
ps = makeParamSet(
  makeLogicalParam(id = "fcregr.tbats.use.box.cox", default = FALSE, tunable = TRUE),
  makeLogicalParam(id = "fcregr.tbats.use.trend", default = FALSE, tunable = TRUE),
  makeLogicalParam(id = "fcregr.tbats.use.damped.trend", default = FALSE, tunable = TRUE),
  makeLogicalParam(id = "fcregr.tbats.seasonal.periods", default = FALSE, tunable = TRUE),
  makeIntegerParam(id = "fcregr.tbats.max.p", upper = 10, lower = 0),
  makeIntegerParam(id = "fcregr.tbats.start.p", upper = 5, lower = 1, 
                   trafo = function(x) x*2),
  makeIntegerParam(id = "fcregr.tbats.max.q", upper = 10, lower = 0),
  makeIntegerParam(id = "fcregr.tbats.start.q", upper = 5,lower = 1,
                   trafo = function(x) x*2),
  makeIntegerParam("fcregr.tbats.max.P", lower = 0, upper = 2),
  makeIntegerParam("fcregr.tbats.max.Q", lower = 0, upper = 2),
  makeDiscreteParam("fcregr.tbats.ic", values = c("aic","bic")),
  makeDiscreteParam("fcregr.tbats.test", values = c("kpss","adf")),
  makeDiscreteParam("fcregr.tbats.seasonal.test", values = c("ocsb", "ch")),
  makeLogicalParam("fcregr.tbats.biasadj", default = FALSE),
  makeDiscreteParam("fcregr.garch.model", values = c("sGARCH","csGARCH")),
  makeIntegerVectorParam(id = "fcregr.garch.garchOrder",
                         len = 2L,
                         lower = 0L,
                         upper = 2L,
                         tunable = TRUE),
  makeLogicalParam(id = "fcregr.garch.include.mean",
                   default = FALSE,
                   tunable = TRUE),
  makeDiscreteParam("fcregr.garch.distribution.model", values = c("snorm","sged")),
  makeDiscreteLearnerParam("fcregr.garch.solver", values = c("nloptr"))
)
```

Using an ML Model: Ensemble Forecasts Super Learner Parameter Set
=========================================

```{r superset, cache = TRUE}
super.ps = makeParamSet(
  makeIntegerLearnerParam("committees", lower = 1, upper = 100),
  makeIntegerLearnerParam("rules", lower = 40, upper = 80),
  makeIntegerLearnerParam("neighbors", lower = 0, upper = 2)
)
ctrl = makeTuneControlIrace(maxExperiments = 300L, n.instances = 50L, minNbSurvival = 2L)
super.mod = makeTuneWrapper(makeLearner("regr.cubist"), resampling = resamp.super,
                            par.set = super.ps, control = ctrl )
```

Using an ML Model: Ensemble Forecasts Sampling Scheme
=========================================

class: small-code 
```{r ensembleResample, cache = TRUE}
resamp.sub = makeResampleDesc("GrowingCV",
                          horizon = 35L,
                          initial.window = .75,
                          size = nrow(getTaskData(climate.task)),
                          #skip = .01
                          )
                          
resamp.super = makeResampleDesc("CV", iters = 20)
```

Using an ML Model: Ensemble Forecasts
=========================================
class: small-code 
```{r ensembleStackLearner, cache = TRUE}
base = c("fcregr.tbats", "fcregr.garch")
lrns = lapply(base, makeLearner)
lrns = lapply(lrns, setPredictType, "response")
lrns[[1]]$par.vals$h = 35
lrns[[2]]$par.vals$n.ahead = 35
stack.forecast = makeStackedLearner(base.learners = lrns,
                       predict.type = "response",
                       method = "average")
```

Using an ML Model: Ensemble Forecasts Tune
=========================================
class: small-code 
```{r ensembleStackLearner, cache = TRUE}
library("parallelMap")
parallelStartSocket(7)
fore.tune = tuneParams(stack.forecast, climate.task, resampling = resamp.sub,
                   par.set = ps, control = ctrl,
                   measures = mase)
parallelStop()
```


```{r ensembleTrain, cache = TRUE}
super.ps = makeParamSet(
  makeIntegerParam("ntree", lower = 500, upper = 1000),
  makeIntegerParam("mtry", lower = 1, upper = 2),
  makeIntegerParam("nodesize",lower = 1, upper = 200),
  makeLogicalParam("replace")
)
ctrl = makeTuneControlIrace(maxExperiments = 1000L)
super.mod = makeTuneWrapper(makeLearner("regr.randomForest"), resampling = resamp.super,
                            par.set = super.ps, control = ctrl, measure = mase )

# Now we will tune a super learner over the base learners
stack.forecast = makeStackedLearner(base.learners = lrns,
                       predict.type = "response",
                       method = "growing.cv",
                       resampling = resamp.sub,
                       super.learner = super.mod)

stack.forecast.tune  = setHyperPars2(stack.forecast,fore.tune$x)
stack.forecast.tune
#start parallel
library("parallelMap")
parallelStartSocket(7)
stack.forecast.mod = train(stack.forecast.tune,climate.task)
parallelStop()
stack.forecast.pred = predict(stack.forecast.mod, newdata = m4Test1)
stack.forecast.pred
performance(stack.forecast.pred, task = climate.task, measure = mase)
matplot(stack.forecast.pred$data,type = "l")
matplot(stack.forecast.pred$data, type = "l")
```
