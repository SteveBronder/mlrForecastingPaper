{
    "collab_server" : "",
    "contents" : "\\documentclass[article]{jss}\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%% declarations for jss.cls %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n%% almost as usual\n\\author{Steve Bronder\\\\ Columbia University}\n\\title{Time Series Methods in the R package \\pkg{MLR}}\n\n%% for pretty printing and a nice hypersummary also set:\n\\Plainauthor{Steve Bronder} %% comma-separated\n\\Plaintitle{Time Series Methods in the R package \\pkg{mlr}} %% without formatting\n\\Shorttitle{\\pkg{mlr}: Time Series Methods} %% a short title (if necessary)\n\n%% an abstract and keywords\n\\Abstract{\n  The MLR package is a unified interface for machine learning tasks such as classification, regression, cluster analysis, and survival analysis. \\pkg{mlr} handles the data pipeline of pre-processing, resampling, model selection, model tuning, and prediction. This paper details new methods for developing time series  models in the \\pkg{mlr}.  Standard and novel tools such as auto-regressive and LambertW transform data generating processes, fixed and growing window cross validation, and forecasting models in the context of univariate and multivariate time series. Examples from forecasting competitions will be given in order to demonstrate the benefits of a unified framework for machine learning and time series.\n}\n\\Keywords{time series, model building, tuning parameters, \\proglang{R}}\n\\Plainkeywords{time series, model building, tuning parameters, R} %% without formatting\n%% at least one keyword must be supplied\n\n%% publication information\n%% NOTE: Typically, this can be left commented and will be filled out by the technical editor\n%% \\Volume{50}\n%% \\Issue{}\n%% \\Month{June}\n%% \\Year{2016}\n%% \\Submitdate{2012-06-04}\n%% \\Acceptdate{2012-06-04}\n\n%% The address of (at least) one author should be given\n%% in the following format:\n\\Address{\n  Steve Bronder\\\\\n  Quantitative Methods in the Social Sciences\\\\\n  Columbia University in the City of New York\\\\\nInternational Affairs Building, MC3355\\\\\n420 W 118th St, Suite 807 \\\\\nNew York, NY 10027\\\\\n  E-mail: \\email{sab2287@columbia.edu}\\\\\n  URL: \\url{insert.url}\n}\n%% It is also possible to add a telephone and fax number\n%% before the e-mail in the following format:\n%% Telephone: +43/512/507-7103\n%% Fax: +43/512/507-2851\n\n%% for those who use Sweave please include the following line (with % symbols):\n%\\usepackage{Sweave}\n\n%% end of declarations %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\n\\begin{document}\n\n%% include your article here, just as usual\n%% Note that you should use the \\pkg{}, \\proglang{} and \\code{} commands.\n\n\\section{Introduction}\n\nThere has been a rapid developement in time series methods over the last 25 years ~\\cite{Hyndman25}. Time series models have not only become more common, but more complex. The \\proglang{R} language ~\\cite{Rbase} has a large task view with many packages available for forecasting and time series methods. However, without a standard framework, many packages have their own sub-culture of style, syntax, and output. The \\pkg{mlr} ~\\cite{mlr} package, short for Machine Learning in R, works to give a strong syntatic framework for the modeling pipeline. By automating many of the standard tools in machine learning such as preprocessing and cross validation, \\pkg{mlr} reduces error in the modeling process that is derived from the user. \n\nWhile there are some time series methods available in the \\pkg{caret} ~\\cite{caret}, development of full on forecasting models in \\pkg{caret} is difficult due to computational constraints and design choices. The highly modular structure of \\pkg{mlr} makes it the best choice for implementing time series methods and models. This paper will show how using \\pkg{mlr}'s strong syntatic structure allows for time series packages such as \\pkg{forecast} ~\\cite{HyndForecast} and \\pkg{rugarch} ~\\cite{rugarch} to use machine learning methedologies such as automated parameter tuning, data preprocessing, model blending, cross validation, performance evaluation, and parallel processing techniques for decreasing model build time.\n\n\\section{Forecasting Example with the M4 Competition}\n\nProfessional forecasters attempt to predict the future of a series based on its past values. Forecasting can be used in a wide range of fields. Examples include forecasting stock prices, ~\\cite{GRANGER19923}, weather patterns ~\\cite{MurphymeteoForecast}, international conficts ~\\cite{Chadefaux01012014}, and earthquakes ~\\cite{earthquakeYegu}. In order to evaluate \\pkg{mlr}'s forecasting framework we need a large set of possible time series to make sure our methods generalize well.\\footnote{Very goofy sentence need to fix}\nThe Makridakis competitions ~\\cite{Makridakis2000451} are forecasting challenges organized by the International Institute of Forecasters and led by Spyros Makridakis to evaluate and compare the accuracy of forecasting methods. The most recent of the competitions, the M4 competition, contains 10,000 time series on a yearly, quarterly, monthly, and daily frequency and areas such as finance, macroeconomics, microeconomics, and industry. For our purposes we will look at two particular daily financial series, one with 9136 observations from April 10th, 1971 to April 13th, 1996 and another with 6742 observations from January 7th, 1981 to June 23rd, 1999. Each series has a forecasting of 328 and 242 periods into the future, respectively.\n\n<<get_dat, cache = TRUE, fig.height= 4, fig.width=4, fig.align='center', echo = FALSE>>=\nlibrary(M4comp)\nlibrary(xts)\nlibrary(lubridate)\nm4Fin1 <- M4[[28]]\nm4Train1 <- xts(m4Fin1$past, as.POSIXct(\"1971-04-10\") + days(0:I(length(m4Fin1$past)-1)))\nm4Test1 <- xts(m4Fin1$future, as.POSIXct(\"1996-01-15\") + days(0:I(length(m4Fin1$future)-1)))\ncolnames(m4Train1) <- \"target_var\"\ncolnames(m4Test1) <- \"target_var\"\n\nm4Fin2 <- M4[[29]]\nm4Train2 <- xts(m4Fin2$past, as.POSIXct(\"1981-01-07\") + days(0:I(length(m4Fin2$past)-1)))\nm4Test2 <- xts(m4Fin2$future, as.POSIXct(\"1999-06-23\") + days(0:I(length(m4Fin2$future)-1)))\ncolnames(m4Train2) <- \"target_var\"\ncolnames(m4Test2) <- \"target_var\"\nplot(m4Train1, main = \"Daily Financial Data One\")\nplot(m4Train2, main = \"Daily Financial Data Two\")\n@\n\nThese two series were chosen for their large time features and stark contrast. Our data set should be large enough that the tuning method can take multiple windows of the data. Some series in M4 only contain 12 observations, which is not enough data to accurately train a model. These two time series were chosen as they are the two largest ones in the M4 competitions data set. We can see figure one is what most people imagine when they think of a time series. Figure two shows a series which appears to have a sort of step feature. The stark difference between the time process of the two series will allow us to investigate whether the methods in \\pkg{mlr}'s forecasting framework can find the appropriate model. The data can be found in the package \\pkg{M4comp} ~\\cite{m4comp} under sets `M4[28]` and `M4[29]. \n\n\\section{Forecasting Tasks}\n\nFrom a development perspective, it is a good idea to form a rigorous framework to define the data and relevant information about a particular predictive task. For forecasting tasks, this is handled in \\pkg{mlr} by the function \\code{makeForecastRegrTask()}. The forecasting task inherets from \\code{makeRegrTask()}, but has two noticable differences in parameters.\n\n\\begin{itemize}\n\\item[data:] Instead of a data frame, an xts object from \\pkg{xts} ~\\cite{xts} containing the time series.\n\\item[frequency:] An integer with the number of periods your time series contains. For example, daily data with a weekly periodicity has a frequency of 7 while daily data with a yearly frequency have a frequency of 365.\n\\end{itemize}\n\n<<fin_task, eval = FALSE>>=\nFin.task1 = makeForecastRegrTask(id = \"M4 Finance Data One\",\n                                 data = m4train1,\n                                 target = \"target_var\")\n@\n\n\\section{Resampling with Time}\n\nOverfitting models is one of the most common problems in prediction. Resampling schemes such as cross-validation, bootstrapping, etc. are common in machine learning. When their is a time component to the data, windowing schemes are necessary so that we correctly resample while still validating the time component of the model\\footnote{crap}. Growing and fixed window resampling such as from ~\\cite{hyndman2014forecasting} are now available in the \\code{resampling()} function of \\pkg{mlr}.\n\n\\begin{figure}[h]\n\\caption{Resampling with a window scheme as exampled by caret}\n  \\includegraphics{windowing_pic_caret}\n  \\centering\n\\end{figure}\n%% Note: If there is markup in \\(sub)section, then it has to be escape as above.\n\\clearpage\n\\bibliographystyle{plainnat}\n\\bibliography{thesisbib}\n\n\\end{document}\n",
    "created" : 1474928116063.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "108809806",
    "id" : "A179CC37",
    "lastKnownWriteTime" : 1475019903,
    "last_content_update" : 1475019903184,
    "path" : "~/Documents/School/Columbia/mlrForecastingPaper/mlr_timeseries_26Sept2016.Rnw",
    "project_path" : "mlr_timeseries_26Sept2016.Rnw",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "sweave"
}