\documentclass[12pt]{article}%[final]
\setcounter{secnumdepth}{3}
% if you need to pass options to natbib, use, e.g.:
% \PassOptionsToPackage{numbers, compress}{natbib}
% before loading nips_2016
%
% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{nips_2016}

%\usepackage{nips_2016}

% to compile a camera-ready version, add the [final] option, e.g.:
%\usepackage[final]{nips_2016}
\usepackage{amsmath}
\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{float}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{color,soul}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage[margin=1.5in]{geometry}
\usepackage[english]{babel}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{verbatim}
\usepackage{setspace}
\doublespacing

\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

% Code defs from jss
\newcommand\code{\@codex}
\def\@codex#1{{\normalfont\ttfamily\hyphenchar\font=-1 #1}}
%%\let\code=\texttt
\let\proglang=\textsf
\newcommand{\pkg}[1]{{\fontseries{b}\selectfont #1}}


%\theoremstyle{definition}
%\newtheorem{definition}{Definition}[section]


\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother

\title{Time Series Methods in the R package \pkg{mlr}}

% The \author macro works with any number of authors. There are two
% commands used to separate the names and addresses of multiple
% authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to
% break the lines. Using \AND forces a line break at that point. So,
% if LaTeX puts 3 of 4 authors names on the first line, and the last
% on the second line, try using \AND instead of \And before the third
% author name.

\author{
  Steve Bronder \\
  %Quantitative Methods of the Social Sciences\\
  %Columbia University\\
  %New York City, NY 10027 \\
  \texttt{sab2287@columbia.edu} \\
  %% examples of more authors test etst
   %Department of Computer Science \\
   %Columbia University\\
   %New York City, NY 10027 \\
  %% \AND
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
}

\begin{document}
% \nipsfinalcopy is no longer used

\maketitle

\begin{abstract}
The \pkg{mlr} package is a unified interface for machine learning tasks such as classification, regression, cluster analysis, and survival analysis. \pkg{mlr} handles the data pipeline of preprocessing, resampling, model selection, model tuning, ensembling, and prediction. This paper details new methods for developing time series  models in \pkg{mlr}. It includes standard and novel tools such as autoregressive and LambertW transform data generating processes, fixed and growing window cross validation, and forecasting models in the context of univariate and multivariate time series. Examples from forecasting competitions will be given in order to demonstrate the benefits of a unified framework for machine learning and time series.
  \end{abstract}


\section{Introduction}
There has been a rapid developement in time series methods over the last 25 years ~\cite{Hyndman25} whereby time series models have not only become more common, but more complex. The \proglang{R} language ~\cite{Rbase} has several task views with compiling the packages available for forecasting, time series methods, and applied finance. However, the open source nature of R has left users without a standard framework. Many packages have their own sub-culture of style, syntax, and output. The \pkg{mlr} ~\cite{mlr} package, short for Machine Learning in R, works to give a strong syntatic framework for the modeling pipeline. By automating many of the standard tools in machine learning such as preprocessing and cross validation, \pkg{mlr} reduces error from the user during the modeling process. 

While there are some time series methods available in \pkg{caret} ~\cite{caret}, development of forecasting models in \pkg{caret} is difficult due to computational constraints and design choices within the package. The highly modular structure of \pkg{mlr} makes it the best choice for implementing time series methods and models. This paper will show how using \pkg{mlr}'s strong syntatic structure allows for time series packages such as \pkg{forecast} ~\cite{HyndForecast}, \pkg{rugarch} ~\cite{rugarch}, and \pkg{BigVAR} ~\cite{BigVAR} to use machine learning methedologies such as automated parameter tuning, data preprocessing, model blending, cross validation, performance evaluation, and parallel processing techniques for decreasing model build time.

\section{Forecasting Example with the M4 Competition}
\label{sec:m4data}

Professional forecasters attempt to predict the future of a series based on its past values. Forecasting can be used in a wide range of tasks including forecasting stock prices, ~\cite{GRANGER19923}, weather patterns ~\cite{MurphymeteoForecast}, international conficts ~\cite{Chadefaux01012014}, and earthquakes ~\cite{earthquakeYegu}. In order to evaluate \pkg{mlr}'s forecasting framework we need a large set of possible time series to make sure our methods generalize well.

The Makridakis competition ~\cite{Makridakis2000451} is a set of forecasting challenges organized by the International Institute of Forecasters and led by Spyros Makridakis to evaluate and compare the accuracy of forecasting methods. The most recent of the competitions, the M4 competition, contains 10,000 time series on a yearly, quarterly, monthly, and daily frequency in areas such as finance, macroeconomics, climate, microeconomics, and industry. To show examples of how \pkg{mlr}'s forecasting features works we will look at a particular climate series. The data is daily with the training subset starting on September 6th, 2007 and ending on September 5th, 2009 while the testing subset is from September 6th, 2009 to October 10th, 2009 for a total of 640 training periods and 35 test periods to forecast.

\singlespacing
<<get_dat_weather, cache = TRUE>>=
library(M4comp)
library(xts)
library(lubridate)
m4.climate <- M4[[8836]]
m4.train <- xts(m4.climate$past, as.POSIXct("2007-12-05") + days(0:I(length(m4.climate$past)-1)))
m4.test <- xts(m4.climate$future, as.POSIXct("2009-09-06") + days(0:I(length(m4.climate$future)-1)))
colnames(m4.train) <- "target_var"
colnames(m4.test) <- "target_var"
@

<<plot_dat_weather, cache = TRUE, fig.height= 6, fig.width=8, fig.align='center', echo = FALSE>>=
plot(m4.train, main = "Daily Climate Data",ylab = "Temperature in Celcius")
@
\doublespacing
This series was chosen for its obvious seasonality and time features. Some series in M4 only contain 12 observations, which is not enough data to accurately train a model. The example data set should be large enough that the tuning method can take multiple windows of the data. We can see figure one is what most people imagine when they think of a time series. There is a clear seasonal time trend with individual points moving about the seasonal periods. The data can be found in the package \pkg{M4comp} ~\cite{m4comp} under sets \code{M4[28]} and \code{M4[29]}. 

For multivariate forecasting, we will use the EUStockMarkets data set from the \pkg{datasets} ~\cite{datasets}. It contains a set of DAX, SMI, CAC, and FTSE European stock indices from July 1st, 1991 to August 24th, 1998 totaling 1828 training observations and 32 test observations.

<<get_dat_stocks, cache = TRUE>>=
data("EuStockMarkets")
EuStockMarkets.time = lubridate::date_decimal(as.numeric(time(EuStockMarkets)))
EuStockMarkets  = xts::xts(as.data.frame(EuStockMarkets), order.by = EuStockMarkets.time)
eu.train = EuStockMarkets[1:1828,]
eu.test = EuStockMarkets[1829:1860,]
@

<<plot_dat_stocks, cache = TRUE, fig.height= 6, fig.width=8, fig.align='center', echo = FALSE>>=
col_names = colnames(eu.train)
# Set a color scheme:
tsRainbow <- rainbow(ncol(EuStockMarkets))
# Plot the overlayed series
plot(x = as.zoo(EuStockMarkets), ylab = "Price", main = "Daily Price of European Stock Indices",
col = tsRainbow, screens = 1)
# Set a legend in the upper left hand corner to match color to return series
legend(x = "topleft", legend = col_names,lty = 1, bty = "n",
       col = tsRainbow, text.width = 8,  cex=1.5, pt.cex = 1)
@

Note that each stock index tends to follow a similar, but diverging, trend. This will be important to note when we perform windowing cross validation as it will let us see how well the models adapt to what appears to be nonstationary data.

\section{Univariate and Multivariate Forecasting Tasks}
\label{sec:task}

\section{Univariate Tasks}

\pkg{mlr} uses the S3 object system to clearly define a predictive modeling task. Tasks contain the data and other relevant information such as the task id and which variable you are targeting for supervised learning problems. Forecasting tasks are handled in \pkg{mlr} by the function \code{makeForecastRegrTask()}. The forecasting task inherets most of it's arguments from \code{makeRegrTask}, but has two noticable differences in arguments.

\begin{itemize}
\item[data:] Instead of a data frame, an xts object from \pkg{xts} ~\cite{xts} containing the time series.
\item[frequency:] An integer with the periodicity of the time series. For example, daily data with a weekly periodicity has a frequency of 7, daily data with a yearly periodicity has a frequency of 365, and weekly data with a yearly frequency has a periodicity of 52.
\end{itemize}

\singlespacing
<<climate_task, eval = TRUE, cache=TRUE, message=FALSE, warning=FALSE>>=
library(mlr)

climate.task = makeForecastRegrTask(id = "M4 Climate Data",
                                 data = m4.train,
                                 target = "target_var",
                                 frequency = 183L)
climate.task

@
\doublespacing
Like a regression task, this records the type of the learning problem and basic information about the data set such as the start and end dates, frequency, and whether we have missing values. Note that there are zero features in our task because we only have a target variable, which the model itself will use to build features.

\subsection{Multivariate Tasks}

One common problem with forecasting is that it is difficult to use additional explanatory variables or forecast multiple targets that are dependent on one another. If we are at time $t$ and want to forecast 10 periods in the future, we need to know the values of the explanatory variables at time $t+10$, which is often not possible. A new set of models ~\cite{BigVAR} which treats explanatory variables endogenously instead of exogenously allows us to forecast not only our target, but addititional explanatory variables. This is done by treating all the variables as targets, making them endogeneous to the model. To use these models, we create a multivariate forecasting task. The function \code{makeMultiForecastRegrTask()} has the same arguments as \code{makeForecastRegrTask()} with one exception. The \code{target} argument can contain either a single target variable, multiple target variables, or \code{All} which treats all variables endogeneously.
\singlespacing
<<multivar_task1, cache = TRUE, eval = TRUE, message=FALSE, warning=FALSE>>=

mfcregr.univar.task = makeMultiForecastRegrTask(id = "bigvar",
                                                data = EuStockMarkets,
                                                target = "FTSE",
                                                frequency = 365L)
mfcregr.univar.task
@
\doublespacing

Like \code{makeForecastRegrTask()}, \code{mfcregr.univar.task} has the standard output, but notice now that there are three features. Alternatively, \code{mfcregr.all.task} contains multiple target values with no features. The difference between each of these multivariate tasks is that \code{mfcregr.univar.task} will act similar to \code{makeForecastRegrTask()}, giving the output, predictions, and even using the measures for univariate forecasting tasks. Both of these tasks will still forecast all of the underlying series, which allows us take exogeneous models and treat them endogeneously for n-step forecasts that use additional explanatory variables.

\singlespacing
<<multivar_task2, cache = TRUE, eval = TRUE, message=FALSE, warning=FALSE>>=
mfcregr.all.task = makeMultiForecastRegrTask(id = "bigvar",
                                             data = eu.train,
                                             target = "all",
                                             frequency = 365L)
mfcregr.all.task
@
\doublespacing

\section{Building and Tuning a forecast learner}

\subsection{Univariate Forecasting}

The \code{makeLearner()} function provides a structured model building framework to the several forecasting models currently implimented in \pkg{mlr}. As an example, we will build the Trigonometric exponential smoothing state space model with Box-Cox transformation, ARMA errors, Trend and Seasonal Components (TBATS)~\cite{tbats}.
\begin{comment}
To create the original BATS model we let $y_t^{\omega}$ be a box cox transformed observation with parameter $\omega$. Then let $m_T$ be the seasonal periods, $l_t$ be the local level in the period, $b$ the long term trend with $b_t$ being the short term trend, $s_t^i$ being the $i$th seasonal component, $d_t$ being an ARIMA($p,q$) model with gaussian white noise process $\epsilon_t$. Smoothing parameters are given by $\alpha$, $\beta$, and $\gamma$ and $\phi$ is the damping constant of the trend.

\begin{align}
y_t^{\omega} &= \begin{cases} 
    \frac{y_t^{\omega} - 1}{\omega}, \omega \ne 0\\
    log(y_t), \omega = 0
    \end{cases}\\
y_t^{\omega} &= l_{t-1} + \phi b_{t-1} + \sum_{i=1}^T s_{t-m_i}^i + d_t\\
l_t &= l_{t-1} + \phi b_{t-1} + \alpha d_t \\
b_t &= (1-\phi)b + \phi b_{t-1} + \beta d_t \\
s_t^i &= s_{t-m_i}^i + \gamma_i d_t \\
d_t &= \sum_{i=1}^p \psi_i d_{t-i} + \sum_{i=1}^q \theta_i \epsilon_{t-i} + \epsilon
\end{align}

The trigonometric part of the model comes from the representation of the seasonal components based on fourier series ~\cite{fourierTrans}. Let the stochastic level of the $i$th seasonal component be $s_{j,t}^{(i)}$ and the stochastic growth in the level of the $i$th seasonal component that is needed to describe the change in the seasonal component over time by $s_{j,t}^{*(i)}$. 

\begin{align}
s_t^{(i)} &= \sum_{j=1}^{k_i} s_{j,t}^{(i)}\\
s_{j,t}^{(i)} &= s_{j,t-1}^{(i)} \cos\lambda_j^{(i)} + s_{j,t-1}^{(i)}\sin\lambda_j^{(i)} + \gamma_1^{(i)}d_t\\
s_{j,t}^{*(i)} &= -s_{j,t-1} \sin\lambda_j^{(i)} + s_{j,t-1}^{*(i)}\cos\lambda_j^{(i)} + \gamma_2^{(i)}d_t
\end{align}

The smoothing parameters are defined by $\gamma_1^{(i)}$ and $\gamma_2^{(i)}$ with $\lambda_j^{(i)} = 2\pi j/m_i$ being a trigonometric smoothing parameter associated with the seasonal periods. The parameter $k_i$ is number of harmonics necessary in the $i$th seasonal component. It's possible to show a simpler deterministic representation of the seasonal components by setting the smoothing parameters to zero. The TBATS model is created by replacing the seasonal component $s_t^{(i)}$ in equation 5 with the trigonometric seasonal equations as well as replacing the measure equation in 2 with 

\begin{equation}
y_t^{\omega} = l_{t-1} + \phi b_{t-1} + \sum_{i=1}^T s_{t-1}^{(i)} + d_t
\end{equation}

\end{comment}

TBATS is one of the most well known forecasting models and is available in mlr along with models such as BATS, ARIMA, ETS, several GARCH variants, and autoregressive neural networks. In addition, preprocessing features have been added to allow arbitrary supervised machine learning models to be used in the context of forecasting. To impliment the TBATS model we use  \code{makeLearner()}, supplying the class of learner, order, the number of steps to forecast, and any additional arguments to be passed to \code{tbats} for \pkg{forecast}. 

\singlespacing
<<makeArima, cache = TRUE>>=
tbats.mod =makeLearner("fcregr.tbats", use.box.cox = TRUE,
                      use.trend = TRUE,
                      seasonal.periods = TRUE, max.p = 60, max.q = 60,
                      stationary = FALSE, use.arma.errors = TRUE,
                      h = 35, predict.type = "response")

@
\doublespacing

We can also supply a predict type for forecasting models to either receive point estimates (\code{response}) or point estimates with quantiles of confidence intervals (\code{quantile}). To train the model we simply call train, supplying the forecasting model and task. After training the model it's simple to get our forecasts by calling \code{predict()} with the test data, returning an object containing meta information for the forecasts along with the prediction and test data in columns \code{truth} and \code{response}, respectively.

\singlespacing
<<maketbatsTrain, cache = TRUE>>=
train.tbats= train(learner = tbats.mod, task = climate.task )
predict.tbats = predict(train.tbats, newdata = m4.test)
@
\doublespacing

To measure the performane of TBATS we call \code{performance()} with the Mean Absolute Scaled Error (MASE) ~\cite{Hyndman2006} measure.

\singlespacing
<<measuretbatsTrain, cache = TRUE>>=
performance(predict.tbats, mase, task = climate.task)
@
\doublespacing
MASE has favorable properties for calculating forecast errors relative to measures such as root mean squared error or median relative absolute error. Arguably one of the most important features, it's very interpretable. Let $y_t$ and $\tilde{y_t}$ be the target variable and prediction at time $t$ until the final time $T$ with $\epsilon_t = y_t - \tilde{y_t}$ being the forecast error. 

\begin{equation}
\text{MASE} = \frac{\sum_{t=1}^T |\epsilon_t|}{\frac{T}{T-1} \sum_{t=2}^T |y_{t, \text{insample}} - y_{t-1, \text{insample}}|}
\end{equation}

Where the denominator is the one step ahead naive forecast from the training data. When the numerator is equal to the denominator the model performed as good as a simple naive forecast method. Scores greater than one mean you are performing worse and scores less than one mean you are performing better than the naive forecasting method.

The scale invariance of MASE means that it is independent of the scale of the data which allows models to be compared across data sets. The scale invariance of MASE has made it a favorite for comparing the accuracy of forecast methods ~\cite{noteMase} across datasets. While scaling in measures such as the Mean Absolute Percentage Error can cause poor behavior as the target variable goes to zero, MASE does not become skewed when the target variable approaches zero. This allows MASE to be use in situations in which zeros occur frequently or zero is not meaningful such as predicting temperature. 

\singlespacing
<<plotbatsTrain, cache = TRUE, fig.height= 6, fig.width=8, fig.align='center', echo = FALSE>>=
pred.tbat.dat = zoo(predict.tbats$data, order.by = index(m4.test))
col_names = colnames(pred.tbat.dat)
# Set a color scheme:
tsRainbow <- rainbow(ncol(pred.tbat.dat))
# Plot the overlayed series
plot(x = pred.tbat.dat, ylab = "Temperature", main = "Forecast of Temperature",
col = tsRainbow, screens = 1)
# Set a legend in the upper left hand corner to match color to return series
legend(x = "bottomleft", legend = col_names,lty = 1, bty = "n",
       col = tsRainbow, text.width = 8,  cex=1, pt.cex = 1)
@
\doublespacing

Need to talk about results

Because the forecasts are only for the next 35 periods it's useful to be able to update the model continuously without retraining the model each time we want new forecasts. Univariate forecasting models in \pkg{mlr} can be updated using \code{updateModel()}. 

\singlespacing
<<tbatsupdate, cache = TRUE>>=
update.tbats = updateModel(train.tbats, climate.task, newdata = m4.test)
predict(update.tbats, task = climate.task)
@
\doublespacing

\subsection{Multivariate Forecasting}

The package \pkg{BigVAR} has been implemented for multivariate forecasting. \pkg{BigVAR} allows for estimation of high dimensional time series through including structured Lasso penalties to the vector autoregression framework~\cite{bigvarpaper}. 

\singlespacing
<<bigVarmod, cache=TRUE, message=FALSE, error=FALSE>>=
bigvar.mod = makeLearner("mfcregr.BigVAR",p = 25, struct = "SparseLag",
                         gran = c(50, 60),h = 35, n.ahead = 35)
@


<<bigVartrain, cache=TRUE, message=FALSE, error=FALSE, eval=FALSE>>=
train.bigvar = train(learner = bigvar.mod, task = mfcregr.all.task )
@

<<bigVartrainreal, cache=TRUE, message=FALSE, error=FALSE, echo = FALSE>>=
load("./bigvarmod.RData")
train.bigvar

@
\doublespacing

Predictions for \code{multiForecast} methods have a similar output to \code{multiclass} methods, returning multiple truth and response variables. A multivariate version of MASE has been implimented which takes the mean of each MASE score for the individual variables.

\singlespacing
<<bigVarpred, cache=TRUE, message=FALSE, error=FALSE>>=
predict.bigvar = predict(train.bigvar, newdata = eu.test)
predict.bigvar
performance(predict.bigvar, multivar.mase, task = mfcregr.all.task)
@

<<bigVarplot, cache=TRUE, message=FALSE, error=FALSE, fig.height= 6, fig.width=8, fig.align='center', echo = FALSE>>=
pred.bigvar.dat = zoo(predict.bigvar$data, order.by = index(eu.test))
col_names = colnames(pred.bigvar.dat)
# Set a color scheme:
tsRainbow <- rainbow(ncol(pred.bigvar.dat))
# Plot the overlayed series
par(xpd = TRUE)
plot(x = pred.bigvar.dat, ylab = "Price", main = "Forecast of Prices for Euro Stock Indices",
col = tsRainbow, screens = 1)
# Set a legend in the upper left hand corner to match color to return series
legend("topleft", legend = col_names[1:4],lty = 1, bty = "n",
       col = tsRainbow[1:4], text.width = 500000, cex = .8,
       ncol = 4)
legend("bottomleft", legend = col_names[5:8],lty = 1, bty = "n",
       col = tsRainbow[5:8], text.width = 600000, cex=.8,
       ncol = 4)

@
\doublespacing

\section{Resampling with Time}

While TBATS is one of the most well known time series models, the order selection process or the ARIMA errors and whether to include trend, damped trend, or seasonal periods can be a subjective process that makes finding the best model difficult for users. One of the first proposals for automated forecasting methods comes from ~\cite{hannanOrder} for automatic order selection of ARIMA models. Innovations are obtained by fitting high order autoregressive models to the data and then computing the likelihood of potential models through a series of standard regresssions. Proprietary algorithms from software such as \proglang{Forecast Pro} ~\cite{forecastpro} and \proglang{Autobox} ~\cite{reillyautobox} are well known and have performed to high standards in competitions such as the M3 forecasting competition ~\cite{Makridakis2000451}. One of the most well known R packages for automated forecast is \pkg{forecast} ~\cite{HyndForecast} which contains several methods for automated forecasting including exponential smoothing based methods and step-wise algorithms for forecasting with ARIMA models.

Forecasting in \pkg{mlr} takes a machine learning approach, creating a parameter set for a given model and using an optimization method to search over the parameter space. To do this, we will use a windowing resampling scheme to train over the possible models. Resampling schemes such as cross-validation, bootstrapping, etc. are common in machine learning for dealing with the bias-variance tradeoff ~\cite{Friedman1997} ~\cite{rodriguezkfold}. When their is a time component to the data, windowing schemes are useful in allowing a valid resampling scheme while still maintaining the time properties of the series. Figure one gives an example of fixed and growing windows. Given a horizon and initial starting point the window slides forward one step each time while either shifting in the fixed case or enlarging by one in the growing case. Growing and fixed window resampling such as from ~\cite{hyndman2014forecasting} are now available in the \code{resampling()} function of \pkg{mlr}. 

\begin{figure}[ht]
\caption{Resampling with a window scheme as exampled by caret ~\cite{windowingcaret}. The top graphs are fixed window cross validation while the bottom graphs are growing window cross validation. }
  \includegraphics[scale = .23]{windowing_pic_caret}
  \centering
\end{figure}
%% Note: If there is markup in \(sub)section, then it has to be escape as above.
\newpage

A windowing resampling process is created in the function \code{makeResampleDesc()} by supplying the resampling type, horizon, initial window, the length of the series, and an optional argument to skip over some windows for the sake of time.

\singlespacing
<<makeResampleDesc, cache = TRUE>>=
resampDesc = makeResampleDesc("GrowingCV", horizon = 35L,
                               initial.window = .7,
                               size = nrow(getTaskData(climate.task)),
                               skip = .004)
resampDesc
@
\doublespacing


To make a parameter set to tune over \pkg{mlr} uses \pkg{ParamHelpers} ~\cite{paramhelper}. There are several types of tools to help us search our parameter space including grid search, random search ~\cite{Bergstra}, to search our parameter space for the most optimal model.


\singlespacing                                      
<<makeparSet, eval = FALSE>>=
parSet = makeParamSet(
           makeLogicalParam(id = "use.box.cox",default = FALSE,
                            tunable = TRUE),
           makeLogicalParam(id = "use.trend", default = FALSE,
                            tunable = TRUE),
           makeLogicalParam(id = "use.damped.trend", default = FALSE,
                            tunable = TRUE),
           makeLogicalParam(id = "seasonal.periods", default = FALSE,
                            tunable = TRUE),
           makeIntegerParam(id = "max.p", upper = 30, lower = 1,
                            trafo = function(x) x*2),
           makeIntegerParam(id = "start.p", upper = 30, lower = 1,
                            trafo = function(x) x*2),
           makeIntegerParam(id = "max.q", upper = 30, lower = 1,
                            trafo = function(x) x*2),
           makeIntegerParam(id = "start.q", upper = 5, lower = 0,
                            trafo = function(x) x*2),
           makeIntegerParam("max.P", lower = 0, upper = 5),
           makeIntegerParam("max.Q", lower = 0, upper = 5),
           makeDiscreteParam("ic",values = c("aicc","aic","bic")),
           makeDiscreteParam("test",values = c("kpss","adf","pp")),
           makeDiscreteParam("seasonal.test",
                            values = c("ocsb", "ch")),
          makeLogicalParam("biasadj", default = FALSE)
        )

#Specify tune by grid estimation
ctrl = makeTuneControlIrace(maxExperiments = 500L)
@
\doublespacing

Using \code{tuneParams()} the model is tuned for the task using the specified resampling scheme, parameter set, tune control, and measure. The \code{trafo} argument allows the tuning process to take values on a seperate scale than the one described. In the tuning scheme above, trafo will look search over $1, 4, 9, ..., 81$, and $100$ values of lag, selecting the model with the best lag structure. For this tuning task we use MASE ~\cite{Hyndman2006} as a measure of performance \footnote{Models with a seasonal difference $> 0$ may be favorably biased as we use the non-seasonal MASE score}.

\singlespacing
<<tuneparam, eval = FALSE>>=
#
library("parallelMap")
parallelStartSocket(8)
configureMlr(on.learner.error = "warn")
set.seed(1234)
tbatsTune = tuneParams(makeLearner("fcregr.tbats", h = 35),
                       task = climate.task, resampling = resampDesc,
                       par.set = parSet, control = ctrl, measures = mase)
parallelStop()
tbatsTune$y

@

<<loadTuneTbats,echo = FALSE, cache = TRUE>>=
load("./tbatsTune.RData")
tbatsTune$y
@

Using \pkg{mlr}'s built in plotting routines the tuning parameters can be analyzed graphically using partial dependence plots ~\ref{partialdep}. Because of constraints which do not allow logical types in the partial dependence plots, the below code takes all of the logical parameters from \code{tbatsTune} and coerces them to numeric.

<<loadTuneTbats2, cache = TRUE, fig.height= 6, fig.width=8, fig.align='center', echo = FALSE>>=
tbats.hyp = generateHyperParsEffectData(tbatsTune, partial.dep = TRUE,
                                        trafo = TRUE)
for (i in 1:4)
 tbats.hyp$data[,i] = as.numeric(tbats.hyp$data[,i])
tbats.hyp$data[,14] = as.numeric(tbats.hyp$data[,14])
plotHyperParsEffect(tbats.hyp, x= "max.q", y = "mase.test.mean",
                     plot.type = "line",
                     partial.dep.learn = "regr.randomForest")

@
\doublespacing

For this model the best maximum number of moving average coefficients is two. The best model's parameters are extracted using \code{setHyperPars()} and passed to \code{train()} to go over the full data set.

\singlespacing
<<bestmodtrain, cache = TRUE>>=
lrn = setHyperPars(makeLearner("fcregr.tbats", h = 35),
                   par.vals = tbatsTune$x)
m = train(lrn, climate.task)
@
\doublespacing

To make predictions for our test set we simply pass our model, task, and test data to \code{predict()}

\singlespacing
<<predbestArima, cache = TRUE>>=
climate.pred = predict(m, newdata = m4.test)
performance(climate.pred, measures = mase, task = climate.task)
@
\doublespacing

For comparison, TBATS is run in \pkg{forecast} with it's base parameters

\singlespacing
<<forecastTbats, cache = TRUE, message=FALSE, warning=FALSE>>=

library(forecast)
forecast.train.tbats = tbats(ts(m4.train,frequency = 365))
forecast.tbats = forecast(forecast.train.tbats,h=35)
# Calculate MASE
sum(abs(coredata(m4.test)-forecast.tbats$mean)) / 
 ((nrow(m4.test) / (nrow(m4.test) + 1)) *
     sum(abs(diff(coredata(m4.test)))))

@
\doublespacing

Now it's possible to see the clear benefit of the forecast extension to \pkg{mlr}. While \pkg{forecast} does some automated tuning, this model would still require extensive manual testing in an attempt to find the best model. By automating this process we come to a faster solution with minimal work.

<<plottbatsTune, cache = TRUE, echo = FALSE>>=

pred.tbat.dat = zoo(cbind(climate.pred$data, as.data.frame(forecast.tbats$mean)), order.by = index(m4.test))
colnames(pred.tbat.dat)[3] <- "forecast_tbats" 
col_names = colnames(pred.tbat.dat)
# Set a color scheme:
tsRainbow <- rainbow(ncol(pred.tbat.dat))
# Plot the overlayed series
plot(x = pred.tbat.dat, ylab = "Temperature", main = "Tuned Forecast of Temperature",
col = tsRainbow, screens = 1)
# Set a legend in the upper left hand corner to match color to return series
legend(x = "bottomleft", legend = col_names,lty = 1, bty = "n",
       col = tsRainbow, text.width = 8,  cex=1, pt.cex = 1)

@

To this author's knowledge, this is the first package in \proglang{R} that allows for automated tuning and training of GARCH models ~\cite{garchengels}. It is possible to pass and train multiple types of GARCH models while also tuning the models respective parameters. In this example we also use \code{predict.type = "quantile"} to estimate confidence intervals for the forecast.

\singlespacing
<<tuneGarch, eval = FALSE>>=
par_set = makeParamSet(
  makeDiscreteParam(id = "model", values = c("sGARCH", "csGARCH")),
  makeIntegerVectorParam(id = "garchOrder", len = 2L, lower = c(1,1),
                         upper = c(4,4)),
  makeIntegerVectorParam(id = "armaOrder", len = 2L, lower = c(5,1),
                         upper = c(8,3)),
  makeLogicalParam(id = "include.mean"),
  makeLogicalParam(id = "archm"),
  makeDiscreteParam(id = "distribution.model",
                    values = c("norm","std","jsu")),
  makeDiscreteParam(id = "stationarity", c(0,1)),
  makeDiscreteParam(id = "fixed.se", c(0,1)),
  makeDiscreteParam(id = "solver", values = "nloptr")
)

#Specify tune by grid estimation
ctrl = makeTuneControlIrace(maxExperiments = 400L)

parallelStartSocket(6)
configureMlr(on.learner.error = "warn")
set.seed(1234)
garchTune = tuneParams(makeLearner("fcregr.garch", n.ahead= 35),
                       task = climate.task, resampling = resampDesc,
                       par.set = par_set, control = ctrl,
                       measures = mase)
parallelStop()
garchTune$y
@
\doublespacing

<<loadGarchTune, cache = TRUE, echo = FALSE>>=
load("./garchTune.RData")
garchTune$y

@


Because the partial dependence plots are still in development they do not work well with \code{makeNumericVectorParams()} such as \code{garchOrder} and \code{armaOrder}. Instead of looking at each $p,q$ individually, we simply sum them and look at the maximum coefficient values for the $p,q$ order of the GARCH component and the ARMA component.

\singlespacing
<<makeHyperPlot,cache=TRUE>>=
garch.hyperpar = generateHyperParsEffectData(garchTune,
                    trafo = TRUE, include.diagnostics = FALSE,
                    partial.dep = TRUE)
garch.hyperpar$data = garch.hyperpar$data[
                      -which(garch.hyperpar$data$mase.test.mean ==
                            max(garch.hyperpar$data$mase.test.mean)),]
garch.hyperpar$data$garchOrder1 = garch.hyperpar$data$garchOrder1 +
                                  garch.hyperpar$data$garchOrder2
garch.hyperpar$data$garchOrder2 = NULL
colnames(garch.hyperpar$data)[2] = "garchOrder"
garch.hyperpar$data$armaOrder1 = garch.hyperpar$data$armaOrder1 +
                                 garch.hyperpar$data$armaOrder2
garch.hyperpar$data$armaOrder2 = NULL
colnames(garch.hyperpar$data)[3] = "armaOrder"
garch.hyperpar$data$include.mean = as.numeric(garch.hyperpar$data$include.mean)
garch.hyperpar$data$archm = as.numeric(garch.hyperpar$data$archm)
plotHyperParsEffect(garch.hyperpar, x= "garchOrder", y = "mase.test.mean",
                     plot.type = "line",
                     partial.dep.learn = "regr.randomForest")
plotHyperParsEffect(garch.hyperpar, x= "armaOrder", y = "mase.test.mean",
                     plot.type = "line",
                     partial.dep.learn = "regr.randomForest")
@
\doublespacing

The dependence plots show that for both the GARCH and ARMA orders, as the order is increased, the MASE score decreases. We would most likely find a better model if we allowed the order of the model to increase up to around fifteen or twenty or both. Forecasting models with quantiles are treated the same as any other learner post-tuning. The best hyperparameters are taken and a final model is trained over the entire dataset.

\singlespacing
<<trainGarchTuned1, cache = TRUE>>=
tuned.lrn = setHyperPars(makeLearner("fcregr.garch",
                                     predict.type = "quantile"),
                         par.vals = garchTune$x)
garch.train = train(tuned.lrn, climate.task)
@

<<trainGarchTuned2, cache = TRUE, echo = FALSE>>=
garch.train$learner$par.vals$n.ahead = 35
@

<<trainGarchTuned3, cache = TRUE>>=
climate.pred = predict(garch.train, newdata = m4.test)
climate.pred
performance(climate.pred, measures = mase, task = climate.task)
@

<<trainGarchTuned4, cache = TRUE, echo = FALSE>>=
nn <- ncol(climate.pred$data)
par(xpd = TRUE)
matplot(climate.pred$data,type="l", xlab = "Forecast Horizon", ylab = "Temperature",
        main = "Forecast of Daily Climate Data\n With Confidence Intervals")
legend(-.5,-5.2, c("Truth", "Prediction", "Lower ConfInt .05", "Upper ConfInt .95"),
       col=seq_len(nn),cex=0.8,fill=seq_len(nn), ncol = 4, bty = "n")
@
\doublespacing

The simple model here performs relatively well. The extremes of the test data are almost all within the given bounds of the 95\% confidence interval. With a bit more tuning and perhaps an alternative control for the search over the parameter space, the reader would easily find a better model. While GARCH is excellent at catching the conditional heteroskedasticity of the past series, the TBATS model performs well in terms of catching long or multiseasonal type periods. Section~\ref{sub:stackedUnivar} goes over how to combine forecasting models to make benefit of both models of their strengths.


\section{Forecasting with Machine Learning Models}

\subsection{Forecasting with Regression Tasks}

The forecasting extension of \pkg{mlr} includes a preprocessing function that allows supervised machine learning models. the function \code{createLagDiffFeatures()} allows for $AR(p,d)$ structures to be imbedded in machine learning models.
\singlespacing
<<lagdiffproc, cache= TRUE>>=
climate.regr.task = makeRegrTask(id = "lagged gbm",
                                 data = as.data.frame(m4.train),
                                 target = "target_var")
climate.task.lag = createLagDiffFeatures(climate.regr.task,
                                         lag = 1L:24L,
                                         difference = 1L,
                                         na.pad=FALSE)
climate.task.lag
@
\doublespacing

Notice that \code{createLagDiffFeatures()} returns a new task with the lagged variables as the new features. Once the lagged task is created the model is trained or tuned like any other.

\singlespacing
<<laggbm, cache= TRUE>>=
lag.gbm = makeLearner("regr.gbm", par.vals = list(n.trees = 20000,
                                                  shrinkage = .000001,
                                                  interaction.depth = 15,
                                                  bag.fraction = .7))
gbm.train = train(lag.gbm, climate.task.lag)
@
\doublespacing

The \code{forecast()} function allows machine learning models to do arbitary n-step ahead forecasts. Let the one step ahead forecast be defined by

\begin{equation}
\hat{y}_{t+1} = \sum_{i=1}^p \left(\rho_i \Delta_d y_{i} + \epsilon_{i}\right)
\end{equation}
where $\rho_i$ is the autoregressiver parameter of order $p$ and $d$ is the lag of the difference operator $\Delta$. Then the $n$-step ahead forecast is defined as

\begin{equation}
\hat{y}_{t+n} = \sum_{i=t+1}^{n} \left(\rho_i \Delta_d \hat{y}_{i} + \epsilon_{i}\right)
\end{equation}


\singlespacing
<<forecastgbm2, eval = FALSE>>=
gbm.forecast = forecast(gbm.train, h = 35L,
                        newdata = as.data.frame(m4.test))
performance(gbm.forecast,mase,climate.task.lag)
@
<<forecastgbm3, cache = TRUE, echo = FALSE>>=
load("./gbm_forecast.RData")
gbm.forecast
performance(pred = gbm.forecast,
            measures = mase,
            task = climate.regr.task)
@

\doublespacing

<<forecastgbmplot, cache = TRUE, echo = FALSE>>=
pred.gbm.dat = zoo(gbm.forecast$data, order.by = index(m4.test))
col_names = colnames(pred.gbm.dat)
# Set a color scheme:
tsRainbow <- rainbow(ncol(pred.gbm.dat))
# Plot the overlayed series
plot(x = pred.gbm.dat, ylab = "Price", main = "Tuned Forecast of Temperature",
col = tsRainbow, screens = 1)
# Set a legend in the upper left hand corner to match color to return series
legend(x = "bottomleft", legend = col_names,lty = 1, bty = "n",
       col = tsRainbow, text.width = 8,  cex=1, pt.cex = 1)
@

\subsection{Forecasting with Classification Tasks}

Forecasting for binary or multiclass outcomes~\cite{forecastBinary} is a common problem in the real world. However, research in this area of forecasting only started picking up speed in the last decade~\cite{ElliotBinary}. With a this new extension to \pkg{mlr} researchers now have the ability to take all the classification models in \pkg{mlr} and apply them to the forecasting context. For developing trading strategies, we normally have a discrete set of choices such as to buy, sell, or hold onto a stock. Using forecasting in mlr we can now train classification models that forecast these choices~\cite{foreclassif}. To example this, a simple buy, sell, or hold trading strategy will be built Using the \code{EuStockMarkets}'s DAX index. If the stock goes up by 5\% in a day we will buy, down 5\% we will sell, and otherwise we will hold onto the current stocks we have. 

\singlespacing
<<classlag, cache = TRUE>>=
DAX = EuStockMarkets$DAX/lag(EuStockMarkets$DAX,
                             7,nap.pad = FALSE) - 1
trade.strat = ifelse(DAX > .05, "Buy",
                     ifelse(DAX < -.05, "Sell", "Hold"))
trade.strat = trade.strat[8:1860]
euro.classif.data = data.frame(trade.strat = trade.strat ,
                               row.names = index(trade.strat))
# Note: Error on multiples of the same observation
euro.classif.train = euro.classif.data[1:1838,,drop = FALSE]
euro.classif.test  = euro.classif.data[1839:1853,,drop = FALSE]
classif.task = makeClassifTask(data = euro.classif.train,
                               target = "DAX")
classif.task.lag = createLagDiffFeatures(classif.task,
                                         lag = 1L:565L,
                                         na.pad = FALSE)
classif.learn = makeLearner("classif.boosting", xval = 1,
                            mfinal = 200, minsplit = 10)

@

<<classlagtrain, eval = FALSE>>=
classif.train = train(classif.learn, classif.task.lag)
classif.fc = forecast(classif.train, h=15, newdata = euro.classif.test)
performance(classif.fc)
@

<<classifSave, eval = FALSE, echo = FALSE>>=
save(classif.train, file = "classif_train.RData")
save(classif.fc, file = "classif_fc.RData")
@

<<classlagtrainreal, echo = FALSE, cache = TRUE>>=
load("./classif_train.RData")
load("./classif_fc.RData")
classif.fc
performance(classif.fc)
@
\doublespacing

With the models and methedologies available in \pkg{mlr}, forecasting binary outcomes is now as simple as any other model. These tools can be used for further research in areas such as directions of stock movement~\cite{markClassifStock} and forecasting extreme values ~\cite{Chen2015UsingEV}. 

\section{Lambert W Transforms}

Many machine learning and time series models rely one the assumption that our data or errors fit a normal distribution. This assumption becomes precarious when modeling the asymmetric and fat-tailed data of the real world. Lambert W Transforms are a family of generalized skewed distributions ~\cite{LambertGeneral} that have bijecetive and parametric functions that allow heavy tailed and asymettric data to appear more Gaussian  ~\cite{GaussLam}. 

Let $U$ be a continuous random variable with cdf $F_U(u|\beta)$ and pdf $f_U(u|\beta)$ given $\beta$ is a parameter vector. Define a continuous location-scale random variable $X\sim F_X(x|\beta)$. A locaton-scale skewed Lambert $W\times F_X$ random variable is defined as 
\begin{equation}
test %Z = U\exp\left(\frac{\delta}{2}(U^2)^\right),\; \delta\ge 0
\end{equation}
And the heavy-tailed Lambert $W\times F_X$ random variable can be defined as
\begin{equation}
test %Z = U\exp\left(\frac{\delta}{2}(U^2)^\alpha\right),\; \delta\ge 0\; \alpha > 0
\end{equation}

Given that $U = (X-\mu_X)/\sigma_X$ where $\mu_X$, $\sigma_X$, $\delta$, and $\alpha$ are the mean and standard deviation of X and the parameters to control skewness and asymetry , respectively. When $\delta = 0$, equation 12 reduces to a standard normal distribution. Equation 12 is the general form of Tukey's $h$ distribution ~\cite{ghdist} and the basis for Morgenthaler and Tukey's ~\cite{hhdist} skewed, heavy tailed family of $hh$ random variables.

\begin{equation}
  Z = \begin{cases}
               U\exp\left(\frac{\delta_l}{2}(U^2)^\alpha_l\right),\; \delta_l \ge 0\; \alpha_l > 0\\
               U\exp\left(\frac{\delta_r}{2}(U^2)^\alpha_r\right),\; \delta_r \ge 0 \alpha_r > 0
            \end{cases}
\end{equation}

\singlespacing
<<lambertWplots, cache= TRUE, message=FALSE, echo = FALSE>>=
# Univariate example
library(LambertW)
set.seed(20)
y1 <- rcauchy(n = 500)
out <- Gaussianize(y1, return.tau.mat = TRUE, type = "h" )
x1 <- get_input(y1, c(out$tau.mat[, 1]))  # same as out$input
par(mfrow = c(2,1))
plot(y1, ylab = "", main = "Cauchy Samples")
plot(x1, ylab = "", main =  "Cauchy Samples With Lambert 'h' Transform")
@
\doublespacing

The function \code{Gaussianize} is available in the package \pkg{LambertW} and has been made into a preprocessing function in \pkg{mlr}. Instead of calling \code{makeLearner()} to create a model, the function \code{makePreprocWrapperLambert()} can be used to create the model. Wrapping the model in this way allows the pre-processing function to be intertwined with the model itself. There are opportunities for users to accidentally bias there own results due to improperly applying pre-processing schemes. For instance, if a user demeaned their entire data set and then split the data into train and test subsets, the training data will be biased because demeaning the model over both the train and test data gives the training data information about the mean of the test data. What should happen instead is, the user first splits the data into training and test data, and then demeans each seperatly. But than what about cross-validation? The goal of cross-validation follows the above schema as well and it is very easy for a user, who assumes they have made a good faith attempt to not bias their model, will end up with overconfident results. Making the preprocessing part of the model itself allows \pkg{mlr} to overcome this. 

There will be a step for the training data or subset, for example to demean it, and then there will be a function for prediction on the testing data, or in the example above to demean the test set alone. In the context of Lambert W$\times$ F$()$ transforms, the $h$, $hh$, or $s$ distribution that gaussianizes the data is estimated from the training data. Then the estimated parameter values from the training set are used during prediction to gaussianize the test observations. The code below follows this methedology, creating the model with Lambert preprocessing, training the model, and then performing prediction. The end result to the user appears the same, but a significant amount of bias is reduced in the background.

\singlespacing
<<lambertWtransform, cache = TRUE>>=
# Need to make this more dramatic
lamb.lrn = makePreprocWrapperLambert("classif.lda", type = "h")
lamb.lrn
lamb.trn = train(lamb.lrn,iris.task, subset = 1:120)
lamb.pred = predict(lamb.trn, iris.task, subset = 121:150)

# Do the non-LW version
trn = train(makeLearner("classif.lda"),iris.task, subset = 1:120)
pred = predict(trn, iris.task, subset = 121:150)
performance(lamb.pred)
performance(pred)
@
\doublespacing

\section{Stacking Forecasting Learners}

Stacking is a form of ensemble learning~\cite{ensembleOverview} in which a learning algorithm is trained on the predictions of several other learning algorithms. Let $y_{i,m}$ be the prediction at time $i$ of model $m$. Given an aggregation function $\phi$, a stacked forecast learner~\cite{combineForecast} is represented as

\begin{equation}
\tilde{y}_{i+1} = \phi(\tilde{y}_{i+1,1}, \tilde{y}_{i+1,2},\dots, \tilde{y}_{i+1,m}, \sum_{j=1}^m \epsilon_{i+1,j})
\label{eq:ensemble}
\end{equation}

For a simple $\phi$ such as the ensemble average then equation~\ref{eq:ensemble} becomes

\begin{equation}
\tilde{y}_{i+1} = \frac{\tilde{y}_{i+1,1}, \tilde{y}_{i+1,2},\dots, \tilde{y}_{i+1,m}}{m}
\label{eq:ensembleAverage}
\end{equation}

In section~\ref{sub:stackedUnivar} the simple model average is used to show how stacked forecast models are built in \pkg{mlr}. Section~\ref{sub:multiStack} does a more advanced method of ensemble averaging involving the forecast of endogeneous variables.

\subsection{Stacking Univariate Learners}
\label{sub:stackedUnivar}

For this example the models TBATS, GARCH, and ARFIMA~\cite{arfima} are stacked together and averaged on the climate task data. A resample description is made, and the function \code{makeLearners()} is used to start multiple learners at the same time.

\singlespacing
<<ensembleModel1, cache = TRUE, eval = TRUE>>=

resamp.sub = makeResampleDesc("GrowingCV",
                          horizon = 35L,
                          initial.window = .90,
                          size = nrow(getTaskData(climate.task)),
                          skip = .01
                          )
lrns = makeLearners(c("fcregr.tbats","fcregr.garch",
                      "fcregr.arfima"))
@
\doublespacing

The function \code{makeStackedLearner()} takes the initialized learners and sets the meta information for stacking. This method uses simple model averaging such as~\ref{eq:ensembleAveraging}, however a super learner~\cite{Wolpert92stackedgeneralization} can be used here, where $\phi()$ becomes another machine learning model.

\singlespacing
<<ensembleModel2, cache = TRUE, eval = TRUE>>=
stack.forecast = makeStackedLearner(base.learners = lrns,
                       predict.type = "response",
                       method = "average")
@
\doublespacing

Each of the stacked learners are tuned over the cross product of all model parameters. This leads to a change in design where, given that some models may have the same argument names, the full name of the model is placed before the argument. This leads to longer code, but tuning over the cross product of the models allows for a more honest perspective of how each model interacts in the stack.

\singlespacing
<<ensembleModel3, cache = TRUE, eval = FALSE>>=

# Simple param set for tuning sub learners
ps = makeParamSet(
  makeDiscreteParam("fcregr.tbats.h", values = 35),
  makeDiscreteParam("fcregr.garch.n.ahead", values = 35),
  makeDiscreteParam("fcregr.arfima.h", values = 35),
  makeDiscreteParam("fcregr.arfima.estim", values = "ls"),
  makeDiscreteParam(id = "fcregr.garch.model",
                    values = c("csGARCH")),
  makeIntegerVectorParam(id = "fcregr.garch.garchOrder",
                         len = 2L, lower = c(1),
                         upper = c(6)),
  makeIntegerVectorParam(id = "fcregr.garch.armaOrder",
                         len = 2L, lower = c(1),
                         upper = c(4)),
  makeDiscreteParam(id = "fcregr.garch.distribution.model",
                    values = c("norm","std","jsu")),
  makeDiscreteParam("fcregr.tbats.test",
                    values = c("kpss","adf","pp")),
  makeIntegerParam("fcregr.tbats.max.P", lower = 0, upper = 3),
  makeIntegerParam("fcregr.tbats.max.Q", lower = 0, upper = 2)
)
ctrl = makeTuneControlIrace(maxExperiments = 400L)
## tuning
library(parallelMap)
parallelStartSocket(7)
configureMlr(on.learner.error = "warn")
set.seed(1234)
fore.tune = tuneParams(stack.forecast, climate.task,
                       resampling = resamp.sub,
                       par.set = ps, control = ctrl,
                       measures = mase, show.info = FALSE)
parallelStop()
fore.tune
@

<<ensembleModelReal, cache = TRUE, echo = FALSE, eval = FALSE>>=
save(fore.tune,file="fore_tune.RData")
@


<<ensembleModelReal2, cache = TRUE, echo = FALSE>>=
load("fore_tune.RData")
@
\doublespacing

The rest of the modeling process flows in a way similar to the standard training and predicting schema. the function \code{setHyperPars2()} takes the best parameter models from the tuning process and assigns it to the final model to train over all of the data. Training and prediction are handled in the same manner as univariate forecasters.

\singlespacing
<<ensembleModel4, cache = TRUE, eval = TRUE>>=

# get hyper params
stack.forecast.tune  = setHyperPars2(stack.forecast,fore.tune$x)
# Train the final best models and predict
stack.forecast.mod = train(stack.forecast.tune,climate.task)
stack.forecast.pred = predict(stack.forecast.mod,
                              newdata = m4.test)
stack.forecast.pred
performance(stack.forecast.pred,mase,climate.task)  
@

<<ensembleForecast5, cache = TRUE, echo = FALSE>>=
col_names = colnames(stack.forecast.pred$data)
# Set a color scheme:
tsRainbow <- rainbow(ncol(stack.forecast.pred$data))
# Plot the overlayed series
plot(x = as.zoo(stack.forecast.pred$data), ylab = "Price", main = "Daily Price of European Stock Indices",
col = tsRainbow, screens = 1)
# Set a legend in the upper left hand corner to match color to return series
legend(x = "bottomleft", legend = col_names,lty = 1, bty = "n",
       col = tsRainbow, text.width = 8,  cex=1, pt.cex = 1)
@
\doublespacing

\subsection{Multivariate Stacked Learner}
\label{sub:multiStack}

When there is a single target variable with multiple predictors stacked learning can be used with multivariate forecasters to forecast the predictors and have a machine learning model train over the forecasts of all variables. For this, equation~\ref{eq:ensemble} can be modified to include forecasts of other predictors $x_i,k$ where $k$ is the index for each predictor variable

\begin{equation}
\tilde{y}_{i+1} = \phi(\tilde{y}_{i+1,1},\dots, \tilde{y}_{i+1,m}, \tilde{x}_{i+1,1},\dots, \tilde{x}_{i+1,k}, \sum_{j=1}^m \epsilon_{i+1,j}, \sum_{j=1}^k \epsilon_{i+1,j})
\label{eq:ensembleMulti}
\end{equation}

In the example below, a boosted glm~\cite{glmboost} is used as a super learner over a sparse lag multivariate VAR model to forecast FTSE prices. A resampling strategy is creating for both the underlying stacked learner and the super learner.

\singlespacing
<<multiforecast1, cache = TRUE>>=
multfore.task = makeMultiForecastRegrTask(id = "bigvar", data = eu.train,
                                          target = "FTSE")

resamp.sub = makeResampleDesc("GrowingCV",
                              horizon = 32L,
                              initial.window = .90,
                              size = nrow(getTaskData(multfore.task)),
                              skip = .01
)

resamp.super = makeResampleDesc("CV", iters = 3)
@
\doublespacing

In \code{makeStackedLearner()}, the super learner argument contains the boosted glm model.

\singlespacing
<<multiforecast2, eval = FALSE>>=
base = c("mfcregr.BigVAR")
lrns = lapply(base, makeLearner)
lrns = lapply(lrns, setPredictType, "response")
lrns[[1]]$par.vals$verbose = FALSE


stack.forecast = makeStackedLearner(base.learners = lrns,
                            predict.type = "response",
                            super.learner = makeLearner("regr.glmboost",
                                                        family = "Laplace"),
                            method = "growing.cv",
                            resampling = resamp.sub)
@
\doublespacing

Just as with univariate stacked forecasting models, a parameter set is created for the multivariate VAR model and tuning is done with \code{tuneParams()}.

\singlespacing
<<multiforecast3, eval = FALSE>>=
ps = makeParamSet(
  makeDiscreteParam("mfcregr.BigVAR.p", values = 9),
  makeDiscreteParam("mfcregr.BigVAR.struct", values = "SparseLag"),
  makeNumericVectorParam("mfcregr.BigVAR.gran", len = 2L, lower = 35,
                         upper = 50),
  makeDiscreteParam("mfcregr.BigVAR.h", values = 32),
  makeDiscreteParam("mfcregr.BigVAR.n.ahead", values = 32)
)

## tuning
library(parallelMap)
parallelStartSocket(4)
configureMlr(on.learner.error = "warn")
set.seed(1234)
multfore.tune = tuneParams(stack.forecast, multfore.task,
                           resampling = resamp.sub,
                           par.set = ps, control = makeTuneControlGrid(),
                           measures = mase, show.info = FALSE)
parallelStop()
multfore.tune
@

<<multiforecast4, cache=TRUE, echo = FALSE>>=
load("multfore_tune.RData")
multfore.tune
@
\doublespacing

Once the tuning is complete, the best model can be extracted with \code{setHyperPar2()} and the final model will be trained on all of the data. Since we are using the multivariate model to produce forecasts for an singel variable, univariate MASE is use instead of the multivariate form of MASE.

\singlespacing
<<multiforecast5, eval = FALSE>>=
stack.forecast.f  = setHyperPars2(stack.forecast,multfore.tune$x)
multfore.train = train(stack.forecast.f,multfore.task)
@

<<multiforecast6, cache=TRUE, echo = FALSE>>=
load("multfore_train.RData")
@

<<multiforecast7, cache=TRUE>>=

multfore.pred = predict(multfore.train, newdata = as.data.frame(eu.test))
multfore.pred
performance(multfore.pred, mase, task = multfore.task)
@
\doublespacing
<<multiForecast8, cache = TRUE, echo = FALSE>>=
col_names = colnames(multfore.pred$data)
# Set a color scheme:
tsRainbow <- rainbow(ncol(multfore.pred$data))
# Plot the overlayed series
plot(x = as.zoo(multfore.pred$data), ylab = "Price", main = "Daily Price of European Stock Indices",
col = tsRainbow, screens = 1)
# Set a legend in the upper left hand corner to match color to return series
legend(x = "topleft", legend = col_names,lty = 1, bty = "n",
       col = tsRainbow, text.width = 8,  cex=1, pt.cex = 1)
@

\section{Conclusion}

The results of this paper show that creating a unified interface for forecasting models in \proglang{R} allows for better models through an automated methedology of resampling, preprocessing, model selection, stacking tuning, and training. Building on the wide range of forecasting packages available in \proglang{R}, automating tasks such as windowing cross validation and model selection allow applied forecasters to spend less time dealing with the beauracracy of modeling and more time testing new models. New methods such as multivariate stacked learners, Lambert W transforms, and the ability to create arbitary AR($p,d$) machine learning models allows researchers to easily experiment with new ideas. While the example models here are not perfect, this was mostly due to time. It will be easy for researchers to beat the models created in this paper.

Multivariate stacked learners are quite new, and to this researchers knowledge have not been used in this context. Future research based on this package would involve tuning these models to see how useful they are in the real world. Classification forecast made available in this extension is a very new field, and with the ease of making these models new research in this area can progress much quicker. Updates to this package will include more multivariate and univariate forecast learners as well as new methods to stack models such as Bayesian averaging~\cite{bayesianAverage}.

%\small
\bibliography{thesisbib}{}
\bibliographystyle{plain}

\end{document}